{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM81zDieIoYxOAoiJnU0bb9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fawzy-AI-Explorer/X-From-Scratch/blob/main/Linear_Regression-From_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression From Scratch"
      ],
      "metadata": {
        "id": "0kvJneJdrMQT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Goals\n",
        "In this toturial, we will:\n",
        "\n",
        "- Implement the linear regression model\n",
        "- Implement the gradient descent algorithm to train the model\n",
        "- Implement $R^2 Score$ to calculate the accuracy<br><br>\n",
        "\n",
        "*All from scratch*"
      ],
      "metadata": {
        "id": "saplMwKGrVBQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tools\n",
        "In this toturial, we will make use of:\n",
        "- math, This module provides access to the mathematical functions defined by the C standard\n",
        "- pandas, a Python library used for working with data sets\n",
        "- NumPy, a popular library for scientific computing\n",
        "- seaborn, a Python data visualization library based on matplotlib\n",
        "- Matplotlib, a popular library for plotting data"
      ],
      "metadata": {
        "id": "d2VFcTdTseFO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Suy_k-6rq8gl"
      },
      "outputs": [],
      "source": [
        "import math, copy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Define a linear regressino class.\"\"\"\n",
        "\n",
        "\n",
        "class _LinearRegression():\n",
        "    \"\"\"Representation of a linear regression model.\n",
        "    the model predicts a number form  infinitely many possible outputs.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, learning_rate=1e-4, max_iter=1000):\n",
        "      \"\"\"Initialize the linear regression model\n",
        "\n",
        "        Args:\n",
        "          learning_rage (float) : The number indicates the step in gradient descent.\n",
        "          max_iter (int) : The maximum number of passes over the training data.\n",
        "      \"\"\"\n",
        "      self.learning_rate = learning_rate\n",
        "      self.max_iter = max_iter\n",
        "      self.w, self.b = None, None\n",
        "\n",
        "    def fit(self, X, y, print_history=True):\n",
        "      \"\"\"\n",
        "      Fit linear model with Stochastic Gradient Descent.\n",
        "\n",
        "      Args:\n",
        "        X (ndarray(m, n)) : Training data (m samples & n features).\n",
        "        y (ndarray(m, ))  : Target values (m samples).\n",
        "\n",
        "      Returns:\n",
        "        self (object) : Fitted Estimator.\n",
        "      \"\"\"\n",
        "\n",
        "    def _compute_gradient(self, X, y):\n",
        "        \"\"\"\n",
        "        Computes the gradient for linear regression\n",
        "        Args:\n",
        "          X (ndarray (m,n)): Data, m examples with n features\n",
        "          y (ndarray (m,)) : target values\n",
        "          w (ndarray (n,)) : model parameters\n",
        "          b (scalar)       : model parameter\n",
        "\n",
        "        Returns:\n",
        "          dj_dw (ndarray (n,)): The gradient of the cost w.r.t. the parameters w.\n",
        "          dj_db (scalar):       The gradient of the cost w.r.t. the parameter b.\n",
        "        \"\"\"\n",
        "\n",
        "        m, n = X.shape\n",
        "        dj_dw = np.zeros((n,))\n",
        "        dj_db = 0.\n",
        "\n",
        "        for i in range(m):\n",
        "          f_wb_i = self.predict(X[i])\n",
        "          err = (f_wb_i - y[i])\n",
        "          dj_dw = dj_dw + (err * X[i])\n",
        "          dj_db += err\n",
        "\n",
        "        dj_dw /= m\n",
        "        dj_db /= m\n",
        "\n",
        "        return dj_dw, dj_db\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "      \"\"\"\n",
        "      Predict using the linear model.\n",
        "\n",
        "      Args:\n",
        "        X (ndarray(m, n)) : Samples (m samples & n features).\n",
        "\n",
        "      Returns:\n",
        "        y (ndarray(m, ))  : Returns predicted values.\n",
        "      \"\"\"\n",
        "      if self.w is not None and self.b is not None:\n",
        "        y = np.dot(X, self.w) + self.b\n",
        "      return y\n",
        "\n",
        "    def score(self, X, y):\n",
        "      \"\"\"\n",
        "      Return the coefficient of determination of the prediction.\n",
        "\n",
        "      Args:\n",
        "        X (ndarray(m, n)) : Test samples (m samples & n features).\n",
        "        y (ndarray(m, ))  : True values for X (m samples).\n",
        "\n",
        "      Returns:\n",
        "        score (float) : R2 score of self.predict() w.r.t. y.\n",
        "      \"\"\"\n",
        "      m, n = X.shape\n",
        "      RSS = 0.\n",
        "      TSS = 0.\n",
        "      y_mu = np.mean(y)\n",
        "\n",
        "      for i in range(m):\n",
        "          RSS += (y[i] - self.predict(X[i])) ** 2\n",
        "          TSS += (y[i] - y_mu) ** 2\n",
        "\n",
        "      score = 1 - RSS / TSS\n",
        "      return round(score, 2)\n",
        "\n",
        "    def get_params(self):\n",
        "      \"\"\"\n",
        "      Get parameters for this estimator.\n",
        "\n",
        "      Returns:\n",
        "        params (dict) : Parameter names mapped to their values.\n",
        "      \"\"\"\n",
        "      params = {}\n",
        "      params[\"learning_rate\"] = self.learning_rate\n",
        "      params[\"max_iter\"] = self.max_iter\n",
        "      if self.w is not None:\n",
        "        for i in range(len(self.w)):\n",
        "            p_name = \"w\" + i\n",
        "            params[p_name] = self.w[i]\n",
        "      if self.b is not None:\n",
        "        params[\"b\"] = self.b\n",
        "\n",
        "      return params\n",
        "\n",
        "    def set_params(self, **params):\n",
        "      \"\"\"\n",
        "      Set the parameters of this estimator.\n",
        "\n",
        "      Args:\n",
        "        Estimator parameters.\n",
        "\n",
        "      Returns:\n",
        "        self (estimator instance) : Estimator instance.\n",
        "      \"\"\"\n"
      ],
      "metadata": {
        "id": "57Ab-TcG4Xdo"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}